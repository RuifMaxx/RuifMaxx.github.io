---
layout: post
title:  从贝叶斯的角度理解VAE
categories: time_series
description: 
keywords: time series
---
## 基本思路

首先我们有一批数据样本${ X1,…,Xn }$，其整体用$X$来描述，我们本想根据${X1,…,Xn}$得到$X$的分布$p(X)$，如果能得到的话，那我直接根据$p(X)$来采样，就可以得到所有可能的$X$了（包括${X1,…,Xn}$以外的），这是一个终极理想的生成模型了。当然，这个理想很难实现，于是我们将分布改一改

$$
p(X)=∑ p(X|Z)p(Z)
$$

这里我们就不区分求和还是求积分了，意思对了就行。此时

$$
p(X|Z)
$$

就描述了一个由$Z$来生成$X$的模型，而我们假设Z服从标准正态分布，也就是$p(Z)=N(0,I)$

**现结合VAE原文（Auto-Encoding Variational Bayes）作进一步的说明：**

![image-20210114190320334](https://ruifmaxx.github.io/images/image-20210114190320334.png)

即对$X$的边缘分布的极大似然

$$
p_θ(x)=∫p_θ(z)p_θ(x | z)dz
$$

的积分是难处理的（因此我们无法评估或求导对$X$的边缘分布的极大似然）。

因此真实后验分布

$$
p_θ(z | x)=p_θ(x | z)p_θ(z)/p_θ(x)
$$

也是难处理的（因此不能使用EM算法）.

## EM算法：

未观测变量的学名是“隐变量”(latent variable). 令 $\mathrm{X}$ 表示已观测变量 集, $\mathbf{Z}$ 表示隐变量集, $\Theta$ 表示模型参数. 若欲对 $\Theta$ 做极大似然估计, 则应最大化对数似然

$$
L L(\Theta \mid \mathbf{X}, \mathbf{Z})=\ln P(\mathbf{X}, \mathbf{Z} \mid \Theta)
$$

然而由于 $\mathbf{Z}$ 是隐变量, 上式无法直接求解. 此时我们可通过对 $\mathbf{Z}$ 计算期望, 来最大化已观测数据的对数“边际似然" (marginal likelihood)

$$
L L(\Theta \mid \mathbf{X})=\ln P(\mathbf{X} \mid \Theta)=\ln \sum_{\mathbf{Z}} P(\mathbf{X}, \mathbf{Z} \mid \Theta)
$$

EM (Expectation-Maximization) 算法 [Dempster et al., 1977$]$ 是常用的估计参数隐变量的利器, 它是一种迭代式的方法, 其基本想法是：若参数 $\Theta$ 已知,则可根据训练数据推断出最优隐变量 $\mathbf{Z}$ 的值 $(\mathrm{E}$ 步 $) ;$ 反之, 若$Z$ 的值已知, 则可方便地对参数 $\Theta$ 做极大似然估计 (M 步).

于是, 以初始值 $\Theta^{0}$ 为起点, 对上式可迭代执行以下步骤直至收敘:

- 基于 $\Theta^{t}$ 推断隐变量 $\mathbf{Z}$ 的期望, 记为 $\mathbf{Z}^{t} ;$
- 基于已观测变量 $\mathbf{X}$ 和 $\mathbf{Z}^{t}$ 对参数 $\Theta$ 做极大似然估计, 记为 $\Theta^{t+1}$;

这就是 EM 算法的原型.
进一步, 若我们不是取 $\mathrm{Z}$ 的期望, 而是基于 $\Theta^{t}$ 计算隐变量 $\mathbf{Z}$ 的概率分布 $P\left(\mathbf{Z} \mid \mathbf{X}, \Theta^{t}\right),$ 则 $\mathrm{EM}$ 算法的两个步骤是:

- $\mathrm{E}$ 步 (Expectation): 以当前参数 $\Theta^{t}$ 推断隐变量分布 $P\left(\mathbf{Z} \mid \mathbf{X}, \Theta^{t}\right),$ 并计 算对数似然 $L L(\Theta \mid \mathbf{X}, \mathbf{Z})$ 关于 $\mathbf{Z}$ 的期望

$$
Q\left(\Theta \mid \Theta^{t}\right)=\mathbb{E}_{\mathbf{Z} \mid \mathbf{X}, \Theta^{t}} L L(\Theta \mid \mathbf{X}, \mathbf{Z})
$$

- $\mathbf{M}$ 步 (Maximization): 寻找参数最大化期望似然, 即

$$
\Theta^{t+1}=\underset{\Theta}{\arg \max } Q\left(\Theta \mid \Theta^{t}\right)
$$

简要来说，EM算法使用两个步骤交替计算：第一步是期望(E)步，利用当前估计的参数值来计算对数似然的期望值;第二步是最大化(M)步,寻找能使E步产生的似然期望最大化的参数值.然后，新得到的参数值重新被用于E步，......直至收敛到局部最优解.

事实上，隐变量估计问题也可通过梯度下降等优化算法求解，但由于求和的项数将随着隐变量的数目以指数级上升,会给梯度计算带来麻烦;而EM算法则可看作一种非梯度优化方法.

## 变分下届

![image-20210114210047396](https://ruifmaxx.github.io/images/image-20210114210047396.png)

$\log p_{\boldsymbol{\theta}}(x)$为我们希望求得的边缘分布的极大似然，(1)式说明我们把希望求得的边缘分布的极大似然分成两项。第一项用KL散度去估计真实的后验分布，因为KL散度非负，因此第二项称作变分下届

比如已知概率密度函数p(x)，那么x的期望也就定义为：

$$
\mathbb{E}[x]=\int x p(x) d x
$$

KL散度衡量两个分布间的差异，可以写作：

$$
K L(q(x) \| p(x))=\int q(x) \log \frac{q(x)}{p(x)} d x=\mathbb{E}_{x \sim q(x)}\left[\log \frac{q(x)}{p(x)}\right]
$$

那么变分下届可以写作：

$$
\begin{aligned}
\mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right)&=\int q_{\phi}(\mathbf{z} \mid \mathbf{x}) \log \frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{q_{\phi}(\mathbf{z} \mid \mathbf{x})} d z\\
&=\mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[-\log q_{\phi}(\mathbf{z} \mid \mathbf{x})+\log p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})\right]\\
&=\mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[-\log q_{\phi}(\mathbf{z} \mid \mathbf{x})+\log (p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})p_{\boldsymbol{\theta}}(\mathbf{z}))\right]\\
&=\mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[-\log\frac{q_{\phi}(\mathbf{z} \mid \mathbf{x})}{p_{\boldsymbol{\theta}}(\mathbf{z})}+\log (p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z}))\right]\\
&=-D_{K L}\left(q_{\phi}\left(\mathbf{z} \mid \mathbf{x}^{(i)}\right) \| p_{\boldsymbol{\theta}}(\mathbf{z})\right)+\mathbb{E}_{q_{\phi}\left(\mathbf{z} \mid \mathbf{x}^{(i)}\right)}\left[\log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)} \mid \mathbf{z}\right)\right]
\end{aligned}
$$

第一项为z的先验和后验分布的KL散度，第二项为在z的后验分布内重采样后生成的x的极大似然. 由于真实的后验分布难以求得，我们假设先验分布$p_{\boldsymbol{\theta}}(\mathbf{z})$为标准正态分布，然后最小化KL散度得到后验分布，最大化X的极大似然得到重构误差。

另外一种VAE损失的具体导出方法可以参考下式：

$$
\begin{aligned}
\log p(x) &=\log \int p(x \mid z) p(z) d z \\
&=\log \int \frac{p(x \mid z) p(z)}{q(z \mid x)} q(z \mid x) d z \\
&=\log \mathbb{E}_{q(z \mid x)}\left[\frac{p(x \mid z) p(z)}{q(z \mid x)}\right]
\end{aligned}
$$

根据 Jenson's不等式：

$$
\log p(x) \geq \mathbb{E}_{q(z \mid x)} \log \left[\frac{p(x \mid z) p(z)}{q(z \mid x)}\right]
$$

经过变形后也可以得到变分下届.

**在训练完成进行测试时，不同问题的采样方法略有不同**。latent ode里面通过延长ODE解算器里面z的求解范围去进行生成：![image-20210115000144799](https://ruifmaxx.github.io/images/image-20210115000144799.png)

keras里面作MNIST生成时通过直接在向量中采样z进行生成：

```python
    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample)
```

在VRNN里面使用$h_{t-1}$ 生成$z_t$的先验进行生成：

![image-20210115000759977](https://ruifmaxx.github.io/images/image-20210115000759977.png)

SRNN中我找到的代码[srnn code](https://github.com/Joeltzy/StochasticRNN/blob/master/3_Code/SRNN_LSTM.ipynb)仍然使用推断网络进行生成

![image-20210115000918750](https://ruifmaxx.github.io/images/image-20210115000918750.png)

```python
	def forecasting(self,x,step,y):
        for t in range(x.size(0)):      
			x_t = x[t] 

			#encoder   
			enc_t = self.enc(reversed_a_t_list[t])
			enc_mean_t = self.enc_mean(enc_t)
			enc_std_t = self.enc_std(enc_t)
            
			#prior
			prior_t = self.prior(h_list[t])   
			prior_mean_t = self.prior_mean(prior_t)
			prior_std_t = self.prior_std(prior_t)
            
    		#sampling and reparameterization
			z_t = self._reparameterized_sample(enc_mean_t, enc_std_t)
			z_t_sampled.append(z_t)
            
			#decoder
			dec_t = self.dec(torch.cat([z_t, h_list[t]], 1))            
			dec_mean_t = self.dec_mean(dec_t)
			dec_std_t = self.dec_std(dec_t)
```



## 回归分析中的极大似然

回顾线性回归的公式：θ是系数，X是特征，h(x) 是预测值。

$$
h(x)  = θ_0 +  θ_1x_1 + θ_2x_2 + … + θ_nx_n\\
 h(x) = Σ θ_ix_i(i\in(0,n ))\\
 h(x) = θ^TX = [θ_1,θ_2,θ_3,…,θ_n] * [x_1,x_2,x_3,…,x_n]^T\\
$$

 最终要求是计算出θ的值，并选择最优的θ值构成算法公式，使预测值能够尽可能接近真实值.

 最终要求是计算出θ的值，并选择最优的θ值构成算法公式，使预测值能够尽可能接近真实值.

$y^{(i)}$：某个样本的实际值。

$ θ^TX ^{(i)}$：使用公式求出的某个样本的预测值。

$ε_{(i)}$ ：误差。

由于每个样本的预测值和实际值都存在一定的误差，我们获得如下公式：

$$
y^{(i)}=θ^TX ^{(i)}+ε_{(i)}
$$


所有样本的误差 $ε_{(i)}$ (1 ≤ i ≤ n) 是独立同分布的，服从均值为 0，方差为某个定值的 $б^2$ 的高斯分布。

解释一下上面这个概念。

**a. 独立同分布(i.i.d)**

实际问题中，很多随机现象都可以看做众多因素独立影响的综合反映，往往服从正态分布。

特征X: X1~Xn 是独立同分布的。

每一个样本根据特征计算出的预测值和真实值之间的误差: ε1~εn 也是独立同分布的。

概率论中的一个概念，即一组数据彼此时间互不干扰，在现实环境里随机出现。

独立:比如抛硬币，每次硬币落地这一事件都是独立的, 不会因为之前抛硬币的结果而改变。而如果是从一堆白球中每次取一个黑球这种事件，于随着白球的减少下次取出黑球的概率会不断变大，则不能称每次的取球行为相互独立。

同分布:如果一组数据都是从掷6面色子的结果中获取的，则称样本同分布。如果数据中夹杂着几个掷12面色子的结果，则样本不是同分布的。

**b、中心极限定理**

中心极限定理：只要${x_1,x_2,.....,x_n} $是独立同分布的，那么$y = x_1+x_2+…+x_n$；
 则y服从：均值 = n * ($x_1$~$x_n$ 的均值) = nμ；方差 = n*($x_1$~$x_n$的方差)=$nσ^2$；

∵ 每个样本的预测值和实际值之间的误差ε(i)也是独立同分布的，所以所有误差的和 ε(i) 满足上述的定义。

又∵ 误差的均值为0，这点在b高斯分布中已证明。(模型是最优的，所以所有的实际值必然均匀得落在预测值的上下两侧，最后误差的均值是0)

∴  所有样本的误差ε(i) (1 ≤ i ≤ n) 是独立同分布的，服从均值为 0，方差为某个定值的 $б^2$ 的高斯分布。得证。

#### 似然函数的概念：

**某种样本取得一个参数的可能性，称之为似然函数。**

设: `f(x|θ) `为样本X=x1,x2,x3,…xn的联合概率密度函数,如果观测到的X=x,则称的函数: 

$$
L(θ|x)= f(x | θ)
$$

为似然函数。

即给定样本x情况下，产生参数的可能性=在给定参数θ的情况下,观测到样本x的概率。因此:似然函数就用**联合概率密度函数**来表示。联合概率密度的值等于似然函数的值。

如果X是离散的随机变量，似然函数

$$
L (θ | x) = p_ θ  (X=x)
$$

 比较似然函数在某个参数点处的取值，

$$
p_{ θ_1} (X=x) > p_{ θ_2} (X=x) 
$$

即：

$$
L (θ_1 | x) > L (θ_2 | x)
$$

 则：当θ = θ1时观测到X=x的可能性大于θ = θ2时，说明θ1比θ2更像是θ的真实值。

我们要观测这些参数值中可能性最大的一个似然函数:

$\max L(\theta \mid x)$

即最大似然函数，看它取得最大值时对应的参数 $\theta$ 是多少。

这个 $\theta$ 就是我们最终想要的东西。

理论知识补充完了，接下来先回到最初的式子:

$y^{(i)}=\theta^{\top} X^{(i)}+\varepsilon^{(i)} ;$ 实际值=预测值 + 误差;
即 $\varepsilon^{(i)}=y^{(i)}-\theta^{\top} X^{(i)} $
由于误差是服从高斯分布的，高斯分布的概率密度函数：

$$
f(x)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}
$$

由于 $\varepsilon^{(i)}$ 均值为0, 将 $\varepsilon^{(i)}$ 代入公式得

$$
p\left(\varepsilon^{(i)}\right)=\frac{1}{\sigma \sqrt{2 \pi}} e^{\left(-\frac{\left(\varepsilon^{(i)}\right)^{2}}{2 \sigma^{2}}\right)}
$$

将公式 $\varepsilon^{(i)}=y^{(i)}-\theta^{\top} X^{(i)} $ 代入概率密度函数得

$$
p\left(y^{(i)} \mid x^{(i)} ; \theta\right)=\frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{\left(y^{(i)}-\theta^{T} x^{(i)}\right)^{2}}{2 \sigma^{2}}\right)
$$


即极大似然为：

$$
\begin{aligned}
L(\theta) &=\prod_{i=1}^{m} p\left(y^{(i)} \mid x^{(i)} ; \theta\right) \\
&=\prod_{i=1}^{m} \frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{\left(y^{(i)}-\theta^{T} x^{(i)}\right)^{2}}{2 \sigma^{2}}\right)
\end{aligned}
$$

取对数后：

$$
\begin{array}{l}
\ell(\theta)=\log L(\theta) \\
\qquad \begin{aligned}
&= \log \prod_{j=1}^{n} \frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{\left(y^{(i)}-\theta^{T} X^{(i)}\right)^{2}}{2 \sigma^{2}}\right) \\
&=\sum_{i=1}^{m} \log \frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{\left(y^{(i)}-\theta^{T} x^{(i)}\right)^{2}}{2 \sigma^{2}}\right) \\
&= m \log \frac{1}{\sigma \sqrt{2 \pi}}-\frac{1}{\sigma^{2}} \cdot \frac{1}{2} \sum_{i=1}^{m}\left(y^{(i)}-\theta^{T} X^{(i)}\right)^{2}
\end{aligned}
\end{array}
$$


#### 极大似然和交叉熵的关系

**信息熵和交叉熵：**

在信源中，考虑的不是某一单个符号发生的不确定性，而是要考虑这个信源所有可能发生情况的平均不确定性。若信源符号有n种取值 $: U_{1} \ldots U_{i} \ldots U_{n},$ 对应概率为 $: P_{1} \ldots P_{i} \ldots P_{n},$ 且各种符号的出现彼此独立。这时，信源的平均不确定性应当为单个 符号不确定性$-logP_1$的统计平均值 (E) , 可称为信息嫡, 即:

$$
H(U)=E\left[-\log p_{i}\right]=-\sum_{i=1}^{n} p_{i} \log p_{i}
$$

在信息论中，交叉熵是表示两个概率分布p,q，其中p表示真实分布，q表示非真实分布，在相同的一组事件中，其中，用非真实分布q来表示某个事件发生所需要的平均比特数。从这个定义中，我们很难理解交叉熵的定义。下面举个例子来描述一下：

假设现在有一个样本集中两个概率分布p,q，其中p为真实分布，q为非真实分布。假如，按照真实分布p来衡量识别一个样本所需要的编码长度的期望为：

$$
\mathrm{H}(\mathrm{p})=\sum_{i} p(i) \cdot \log \left(\frac{1}{p(i)}\right)
$$

但是，如果采用错误的分布q来表示来自真实分布p的平均编码长度，则应该是：

$$
\mathrm{H}(\mathrm{p}, \mathrm{q})=\sum_{i} p(i) \cdot \log \left(\frac{1}{q(i)}\right)
$$

此时就将H(p,q)称之为交叉熵。交叉熵的计算方式如下：

对于离散变量粟用以下的方式计算: $\mathrm{H}(\mathrm{p}, \mathrm{q})=\sum_{x} p(x) \cdot \log \left(\frac{1}{q(x)}\right)$
对于连续变量来用以下的方式计算: $-\int_{X} P(x) \log Q(x) d r(x)=E_{p}[-\log Q]$

**满足伯努利分布时交叉熵等于极大似然：**

[最小化交叉熵损失与极大似然 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/51099880)

keras里面作MNIST生成时也是直接使用交叉熵作重构误差。

```python
            reconstruction_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)
                )
            )
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = reconstruction_loss + kl_loss
```

下面这篇文章准确性存疑：

[极大似然估计与最小化交叉熵损失或者KL散度为什么等价？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/84764177)

### 参考链接

[机器学习 (nju.edu.cn)](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/MLbook2016.htm)

[Variational AutoEncoder](https://keras.io/examples/generative/vae/)

[Auto-Encoding Variational Bayes](https://arxiv.org/pdf/1312.6114.pdf)

[变分自编码器（一）：原来是这么一回事 - 科学空间 Scientific Spaces](https://spaces.ac.cn/archives/5253)

[变分自编码器（二）：从贝叶斯观点出发 - 科学空间 Scientific Spaces](https://spaces.ac.cn/archives/5343)

[交叉熵_百度百科 (baidu.com)](https://baike.baidu.com/item/交叉熵/8983241?fr=aladdin)

[02 回归算法 - 线性回归求解 θ（最大似然估计求解） - 简书 (jianshu.com)](https://www.jianshu.com/p/fbd736a61927)

[信息熵_百度百科 (baidu.com)](https://baike.baidu.com/item/信息熵/7302318?fr=aladdin)

[生成时间序列的VAE——VRNN与SRNN模型浅析](https://zhuanlan.zhihu.com/p/272106709)

[最小化交叉熵损失与极大似然 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/51099880)

[极大似然估计与最小化交叉熵损失或者KL散度为什么等价？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/84764177)

[Neural Ordinary Differential Equations](https://arxiv.org/pdf/1806.07366.pdf)